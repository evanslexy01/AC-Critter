{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(p1: tuple[int, int], p2: tuple[int, int]) -> float:\n",
    "    dist = math.sqrt((p2[0] - p1[0])**2 + (p2[1] - p1[1])**2) # distance formula\n",
    "    return(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def editors(sample):\n",
    "    # Makes it one channel\n",
    "    gray = cv2.cvtColor(sample, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Closing operation \n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    img = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel, iterations= 25)\n",
    "\n",
    "    # Filtering and fixing\n",
    "    img = cv2.GaussianBlur(img, (11, 11), 0)\n",
    "    ret, thresh = cv2.threshold(img, 140, 225, cv2.THRESH_BINARY) \n",
    "    \n",
    "    #Finding Canny Lines\n",
    "    canny = cv2.Canny(thresh, 0, 200)\n",
    "    canny = cv2.dilate(canny, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5)))\n",
    "    canny = np.float32(canny) \n",
    "    return(canny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cornerLexy(canny):\n",
    "    dst = cv2.cornerHarris(canny , 5, 3, 0.04)\n",
    "    ret, dst = cv2.threshold(dst, 0.1*dst.max(), 255, 0)\n",
    "    dst = np.uint8(dst)\n",
    "    ret, labels, stats, centroids = cv2.connectedComponentsWithStats(dst)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
    "    corners = cv2.cornerSubPix(canny, np.float32(centroids),(5, 5), (-1, -1), criteria)\n",
    "    return(corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corner_sort(sample,corners):\n",
    "    w = sample.shape[1]\n",
    "    h = sample.shape[0]\n",
    "\n",
    "    df = pd.DataFrame(data = corners)\n",
    "    halfwayx = min(df[0]) + ((max(df[0]) - min(df[0])) / 2)\n",
    "    halfwayy = min(df[1]) + ((max(df[1]) - min(df[1])) / 2)\n",
    "\n",
    "    botl = [item for item in corners if item[0] <= halfwayx and item[1] <= halfwayy]\n",
    "    topl = [item for item in corners if item[0] <= halfwayx and item[1] >= halfwayy]\n",
    "    botr = [item for item in corners if item[0] >= halfwayx and item[1] <= halfwayy]\n",
    "    topr = [item for item in corners if item[0] >= halfwayx and item[1] >= halfwayy]\n",
    "\n",
    "    dist1 = [distance(x, (0, 0)) for x in botl]\n",
    "    dist2 = [distance(x, (0, h)) for x in topl]\n",
    "    dist3 = [distance(x, (w, 0)) for x in botr]\n",
    "    dist4 = [distance(x, (w, h)) for x in topr]\n",
    "\n",
    "    bl = botl[dist1.index(min(dist1))]\n",
    "    tl = topl[dist2.index(min(dist2))]\n",
    "    br = botr[dist3.index(min(dist3))]\n",
    "    tr = topr[dist4.index(min(dist4))]\n",
    "\n",
    "    srccorners = np.array([bl, br, tr, tl], np.float32)\n",
    "    return(bl,br,tl,tr,srccorners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather(bl, br, tl, tr):\n",
    "    widtha = distance(bl, br)\n",
    "    widthb = distance(tl, tr)\n",
    "    mW = int(max(widtha, widthb))\n",
    "\n",
    "    heighta = distance(br, tr)\n",
    "    heightb = distance(bl, tl)\n",
    "    mH = int(max(heighta, heightb))\n",
    "\n",
    "    destcorners = np.array([(0, 0), (mW, 0), (mW, mH), (0, mH)], np.float32)\n",
    "    return(mW,mH,destcorners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persp_match(sample, srccorners, destcorners, mW, mH):\n",
    "    matrix = cv2.getPerspectiveTransform(srccorners, destcorners)\n",
    "    result = cv2.warpPerspective(sample, matrix, (mW, mH))\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(result):\n",
    "    #Thresholding \n",
    "    gray = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh3 = cv2.threshold(gray, 127, 225, cv2.THRESH_BINARY)\n",
    "\n",
    "    #Removing Noise\n",
    "    img2 = cv2.GaussianBlur(thresh3, (11, 11), 0)\n",
    "    canny2 = cv2.Canny(img2, 0, 200)\n",
    "    return(canny2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxer(result,canny2,mW,mH):\n",
    "    center = []\n",
    "    rectangles = []\n",
    "    contours = cv2.findContours(canny2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = contours[0 if len(contours) == 2 else 1]\n",
    "    for cntr in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cntr)\n",
    "        if (w*h >= mW*mH*0.00028) and (w + h <= (mW+mH)*0.1):\n",
    "            cv2.rectangle(result, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "            rectangles.append([x, y, w, h])\n",
    "            center.append((x + (0.5*w), y + (0.5*h)))\n",
    "    return(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartographer(result,mW,mH):\n",
    "    #Put plotting lines into comments so it could be faster, turn back on to see grid lines\n",
    "    #Finding the grid lines\n",
    "    #dx = int((1 / 12) * mW)\n",
    "    #dy = int((1 / 8.4) * mH)\n",
    "    #grid_color = [255, 0, 0]\n",
    "    #result[::dy,:,:] = grid_color\n",
    "    #result[:,::dx,:] = grid_color\n",
    "\n",
    "    #Plot\n",
    "    #plt.imshow(result)\n",
    "    #plt.show()\n",
    "\n",
    "    #Value of those gridlines\n",
    "    x_bounds = np.arange(0, mW, (1 / 12)*mW).tolist()\n",
    "    y_bounds = np.arange(0, mH, (1 / 8.4)*mH).tolist()\n",
    "    return(x_bounds,y_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorter(center,x_bounds,y_bounds):\n",
    "    #Separating the coordinates into x and y\n",
    "    cx = [item[0] for item in center]\n",
    "    cy = [item[1] for item in center]\n",
    "\n",
    "    #Grid numbering\n",
    "    gridx = [sum(1 for b in x_bounds if b < x) for x in cx]\n",
    "    gridy = [sum(1 for b in y_bounds if b < y) for y in cy]\n",
    "    return(gridx,gridy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scanner(imagename):\n",
    "    #Adding the pictures\n",
    "    sample = cv2.imread(imagename, cv2.IMREAD_UNCHANGED)\n",
    "    #All of the things\n",
    "    canny = editors(sample)\n",
    "    corners = cornerLexy(canny)\n",
    "    bl,br,tl,tr,srccorners = corner_sort(sample,corners)\n",
    "    mW,mH,destcorners = gather(bl,br,tl,tr)\n",
    "    result = persp_match(sample, srccorners, destcorners, mW, mH)\n",
    "    canny2 = cleaning(result)\n",
    "    center = boxer(result,canny2,mW,mH)\n",
    "    x_bounds, y_bounds = cartographer(result,mW,mH)\n",
    "    gridx,gridy = sorter(center,x_bounds,y_bounds)\n",
    "    return(gridx,gridy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the functions and what they do: <br>\n",
    "\n",
    "editors - cleans raw file, returns a canny image of the screen without other background elements <br>\n",
    "cornerLexy - determines the corners from the canny image, returns a list of (x,y) corners <br>\n",
    "corner_sort - determines the corners closest to the edges of the image, returns the coordinates of those real corners and srccorners <br>\n",
    "gather - uses the real corner coordinates to find how wide and tall the screen is in the image, returns max width/height and destcorners <br>\n",
    "persp_match - uses srccorners and destcorners, makes the image flat and forward facing to fix any camera tilt/turn, returns an adjusted image <br>\n",
    "cleaning - cleans the content on screen, removes pixelated lines that come with taking a pic of a screen, thresholds so the creatures are black <br>\n",
    "boxer - puts boxes around the black images, calcluates the center of those boxes and returns that as a list of center coordinates (x,y) <br>\n",
    "cartographer - takes the cleaned picture, grids it proportionate to the size, returns the grid line locations for x and y <br>\n",
    "sorter - cycles each center point through the list of grid lines to find which sector it lies in, returns the x sector and y sector of each <br>\n",
    "scanner - runs the sample through all of these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to submit 5 images, one for each of the frames. Picture should not have glare, not on a white background if possible, and without joycons in the frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#sample = cv2.imread('IMG_2233.jpg', cv2.IMREAD_UNCHANGED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# something that allows users to upload 5 pictures\n",
    "# maybe it requests user to do it in a specific order\n",
    "\n",
    "images = ['IMG_2231.jpg', 'IMG_2232.jpg', 'IMG_2207.jpg', 'fish2test.jpg', 'IMG_2233.jpg']\n",
    "collection_df = pd.DataFrame()\n",
    "frames = ('bug1', 'bug2', 'fish1', 'fish2', 'sea')\n",
    "\n",
    "for sample in images:\n",
    "    add_df = pd.DataFrame()\n",
    "    gridx, gridy = scanner(sample)\n",
    "    add_df['X'] = gridx\n",
    "    add_df['Y'] = gridy\n",
    "    add_df['Frame'] = frames[images.index(sample)]\n",
    "    collection_df = pd.concat([collection_df, add_df], ignore_index= True, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing what we have vs the pedia \n",
    "pediadf = pd.read_csv('Pedia.csv')\n",
    "\n",
    "#List with indicator, left-only means missing\n",
    "user_collection = pediadf.merge(collection_df.drop_duplicates(), on=['X','Y','Frame'], how='left', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Users should be able to select their hemisphere, view/add/remove critters from their collection, see what they haven't caught\n",
    "# that they can catch at that date/time, see what date/time they'd be able to catch the most new critters, change the date/time\n",
    "# filter their collections to see caught/uncaught, maybe see percent done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    capture = False\n",
    "    success, frame = cap.read()\n",
    "    cv2.imshow('live', frame)\n",
    "    if cv2.waitKey(1) & 0xFF ==ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
